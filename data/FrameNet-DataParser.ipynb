{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrameNet Data Importer\n",
    "This notebook walks through importing data from [FrameNet's](https://framenet.icsi.berkeley.edu/fndrupal/) XML format into a more analysis-friendly Pandas DataFrame. The data is also saved as a JSON file and as a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(directory, file_name):\n",
    "    \"\"\"\n",
    "    Parses XML from FrameNet, given a file's directory and filename\n",
    "    \n",
    "    Inputs:\n",
    "        directory (string): path to directory where XML file is stored.\n",
    "        file_name (string): file name to parse.\n",
    "        \n",
    "    Output:\n",
    "        (array of dict): an array with dictionaries containing the corpus name, the current document name,\n",
    "            a full sentence, a word, and the assoicated part of speech and semantic frame for that word.\n",
    "    \"\"\"\n",
    "    # all files have a name space\n",
    "    ns = { 'framenet': \"http://framenet.icsi.berkeley.edu\" }\n",
    "    \n",
    "    # get the element tree of the xml file\n",
    "    root = ET.parse(os.path.join(directory, file_name)).getroot()\n",
    "    \n",
    "    # setup output info\n",
    "    output = []\n",
    "    corpus_name, document_name = file_name.replace(\".xml\", \"\").split(\"__\")\n",
    "    \n",
    "    # work through each sentence and setup output\n",
    "    for sentence in root.findall('framenet:sentence', ns):\n",
    "        # get sentence\n",
    "        text = sentence.find('framenet:text', ns)\n",
    "        \n",
    "        # get all annotations_sets for the sentence\n",
    "        for annotation_set in sentence.findall('framenet:annotationSet', ns):\n",
    "            # check if annotation set has a lexical unit (luName) and a frame name (frameName) attribute\n",
    "            attributes = annotation_set.attrib\n",
    "            if \"luName\" in attributes and \"frameName\" in attributes:\n",
    "                # get lexical unit, phrase type, and frame name\n",
    "                lexical_unit, phrase_type = attributes[\"luName\"].split(\".\")\n",
    "                frame_name = attributes[\"frameName\"]\n",
    "                \n",
    "                # convert phrase_type to readable one\n",
    "                phrase_type_lookup = {\n",
    "                    \"n\": \"noun\",\n",
    "                    \"a\": \"adjective\",\n",
    "                    \"v\": \"verb\",\n",
    "                    \"adv\": \"adverb\",\n",
    "                    \"prep\": \"prepositional\",\n",
    "                    \"c\": \"clause\",\n",
    "                    \"art\": \"art\",\n",
    "                    \"num\": \"quantifier\",\n",
    "                    \"idio\": \"idiom\",\n",
    "                    \"scon\": \"subordinate clause with subordinating conjunction\"\n",
    "                }\n",
    "                \n",
    "                'v', 'n', 'a', 'adv', 'prep', 'c', 'art', 'num', 'idio', 'scon'\n",
    "                \n",
    "                # add to output\n",
    "                output.append({\n",
    "                    \"corpus\": corpus_name,\n",
    "                    \"document\": document_name,\n",
    "                    \"sentence\": text.text.strip(),\n",
    "                    \"word\": lexical_unit.strip(),\n",
    "                    \"phrase_type\": phrase_type_lookup[phrase_type.strip()],\n",
    "                    \"semantic_frame\": frame_name.strip()\n",
    "                })\n",
    "    \n",
    "    return output\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data into a Pandas DataFrame, and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68d4de41594482a9305484f4c89b927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>semantic_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>complete</td>\n",
       "      <td>verb</td>\n",
       "      <td>Activity_finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>May</td>\n",
       "      <td>noun</td>\n",
       "      <td>Calendric_unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>June</td>\n",
       "      <td>noun</td>\n",
       "      <td>Calendric_unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>month</td>\n",
       "      <td>noun</td>\n",
       "      <td>Calendric_unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>total</td>\n",
       "      <td>noun</td>\n",
       "      <td>Amounting_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28936</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>Jamaica is an island with a strong personality...</td>\n",
       "      <td>strong</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Level_of_force_exertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28937</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>Jamaica is an island with a strong personality...</td>\n",
       "      <td>wait</td>\n",
       "      <td>verb</td>\n",
       "      <td>Waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28938</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>Jamaica is an island with a strong personality...</td>\n",
       "      <td>wing</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28939</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>It comes out to meet you .</td>\n",
       "      <td>come</td>\n",
       "      <td>verb</td>\n",
       "      <td>Arriving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28940</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>It comes out to meet you .</td>\n",
       "      <td>meet</td>\n",
       "      <td>verb</td>\n",
       "      <td>Make_acquaintance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28941 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              corpus             document  \\\n",
       "0      LUCorpus-v0.3  enron-thread-159550   \n",
       "1      LUCorpus-v0.3  enron-thread-159550   \n",
       "2      LUCorpus-v0.3  enron-thread-159550   \n",
       "3      LUCorpus-v0.3  enron-thread-159550   \n",
       "4      LUCorpus-v0.3  enron-thread-159550   \n",
       "...              ...                  ...   \n",
       "28936            ANC         IntroJamaica   \n",
       "28937            ANC         IntroJamaica   \n",
       "28938            ANC         IntroJamaica   \n",
       "28939            ANC         IntroJamaica   \n",
       "28940            ANC         IntroJamaica   \n",
       "\n",
       "                                                sentence      word  \\\n",
       "0      I have completed the invoices for April, May a...  complete   \n",
       "1      I have completed the invoices for April, May a...       May   \n",
       "2      I have completed the invoices for April, May a...      June   \n",
       "3      I have completed the invoices for April, May a...     month   \n",
       "4      I have completed the invoices for April, May a...     total   \n",
       "...                                                  ...       ...   \n",
       "28936  Jamaica is an island with a strong personality...    strong   \n",
       "28937  Jamaica is an island with a strong personality...      wait   \n",
       "28938  Jamaica is an island with a strong personality...      wing   \n",
       "28939                         It comes out to meet you .      come   \n",
       "28940                         It comes out to meet you .      meet   \n",
       "\n",
       "      phrase_type           semantic_frame  \n",
       "0            verb          Activity_finish  \n",
       "1            noun           Calendric_unit  \n",
       "2            noun           Calendric_unit  \n",
       "3            noun           Calendric_unit  \n",
       "4            noun             Amounting_to  \n",
       "...           ...                      ...  \n",
       "28936   adjective  Level_of_force_exertion  \n",
       "28937        verb                  Waiting  \n",
       "28938        noun        Building_subparts  \n",
       "28939        verb                 Arriving  \n",
       "28940        verb        Make_acquaintance  \n",
       "\n",
       "[28941 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"./fndata/fulltext\"\n",
    "\n",
    "# parse all data\n",
    "parsed_files = []\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    for file in tqdm(files):\n",
    "        if file.endswith(\".xml\"):\n",
    "            parsed_files += parse_xml(root, file)\n",
    "\n",
    "# convert list to dataframe\n",
    "parsed_files_df = pd.DataFrame(parsed_files)\n",
    "parsed_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output directory if needed\n",
    "OUTPUT_DIR = \"./parsed_data\"\n",
    "OUTPUT_FILE = \"parsed_framenet\"\n",
    "OUTPUT_FILE_DIR = os.path.join(OUTPUT_DIR, OUTPUT_FILE)\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# save as pickle\n",
    "parsed_files_df.to_pickle(OUTPUT_FILE_DIR + \".p\")\n",
    "\n",
    "# save as json\n",
    "parsed_files_df.to_json(OUTPUT_FILE_DIR  + \".json\", orient=\"records\")\n",
    "\n",
    "# save as csv\n",
    "parsed_files_df.to_csv(OUTPUT_FILE_DIR + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>semantic_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>complete</td>\n",
       "      <td>verb</td>\n",
       "      <td>Activity_finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>May</td>\n",
       "      <td>noun</td>\n",
       "      <td>Calendric_unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>June</td>\n",
       "      <td>noun</td>\n",
       "      <td>Calendric_unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>month</td>\n",
       "      <td>noun</td>\n",
       "      <td>Calendric_unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LUCorpus-v0.3</td>\n",
       "      <td>enron-thread-159550</td>\n",
       "      <td>I have completed the invoices for April, May a...</td>\n",
       "      <td>total</td>\n",
       "      <td>noun</td>\n",
       "      <td>Amounting_to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          corpus             document  \\\n",
       "0  LUCorpus-v0.3  enron-thread-159550   \n",
       "1  LUCorpus-v0.3  enron-thread-159550   \n",
       "2  LUCorpus-v0.3  enron-thread-159550   \n",
       "3  LUCorpus-v0.3  enron-thread-159550   \n",
       "4  LUCorpus-v0.3  enron-thread-159550   \n",
       "\n",
       "                                            sentence      word phrase_type  \\\n",
       "0  I have completed the invoices for April, May a...  complete        verb   \n",
       "1  I have completed the invoices for April, May a...       May        noun   \n",
       "2  I have completed the invoices for April, May a...      June        noun   \n",
       "3  I have completed the invoices for April, May a...     month        noun   \n",
       "4  I have completed the invoices for April, May a...     total        noun   \n",
       "\n",
       "    semantic_frame  \n",
       "0  Activity_finish  \n",
       "1   Calendric_unit  \n",
       "2   Calendric_unit  \n",
       "3   Calendric_unit  \n",
       "4     Amounting_to  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data from pickle, json, or csv file\n",
    "data_df = pd.read_pickle(OUTPUT_FILE_DIR + \".p\")\n",
    "# data_df = pd.read_json(OUTPUT_FILE_DIR  + \".json\")\n",
    "# data_df = pd.read_csv(OUTPUT_FILE_DIR  + \".csv\")\n",
    "\n",
    "# view first 5 rows of DataFrame\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See unique entries of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LUCorpus-v0.3', 'ANC', 'WikiTexts', 'NTI', 'PropBank',\n",
       "       'Miscellaneous', 'KBEval'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all uniqe corpus names\n",
    "data_df[\"corpus\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['enron-thread-159550', 'HistoryOfLasVegas', 'Fires_5',\n",
       "       'acquisition.n', 'Kazakhstan', 'Fires_4', '602CZL285-1',\n",
       "       'ENRON-pearson-email-25jul02', 'Fires_6', '20000410_nyt-NEW',\n",
       "       'AetnaLifeAndCasualty', '20000415_apw_eng-NEW', 'Fires_7',\n",
       "       'Iran_Introduction', 'NorthKorea_NuclearCapabilities',\n",
       "       'tradeBalance020417', '110CYL200', 'chapter1_911report', 'Fires_3',\n",
       "       'WMDNews_042106', 'AFGP-2002-600002-Trans', 'IranRelatedQuestions',\n",
       "       'LomaPrieta', 'Fires_2', 'SouthAfrica_Introduction',\n",
       "       'WMDNews_062606', 'ElectionVictory', 'cycorp', 'SemAnno_1',\n",
       "       'someone.n', 'Russia_Introduction', 'Fires_1', 'Fires_10',\n",
       "       'workAdvances', 'Tiger_Of_San_Pedro',\n",
       "       'PolemicProgressiveEducation', 'wsj_2465',\n",
       "       'CNN_AARONBROWN_ENG_20051101_215800.partial-NEW',\n",
       "       '20000424_nyt-NEW', 'lcch', 'invoice.n', 'LibyaCountry1',\n",
       "       '112C-L013', 'journal_christine', 'parc', '110CYL070',\n",
       "       'StephanopoulosCrimes', 'MIT', '110CYL072', 'Iran_Nuclear',\n",
       "       'LCC-M', 'C-4Text', 'Taiwan_Introduction', '20000416_xin_eng-NEW',\n",
       "       '110CYL067', 'Hijack', 'HistoryOfGreece', 'extent.n',\n",
       "       'sw2025-ms98-a-trans.ascii-1-NEW', 'NorthKorea_Introduction',\n",
       "       'BellRinging', 'utd-icsi', 'HistoryOfJerusalem', 'Examples4-5',\n",
       "       '110CYL069', 'WhereToHongKong', 'CNN_ENG_20030614_173123.4-NEW-1',\n",
       "       'Orwell_1984_p1', '110CYL068', 'IntroOfDublin',\n",
       "       'EntrepreneurAsMadonna', 'wsj_1640.mrg-NEW', 'TicketSplitting',\n",
       "       'Iran_Biological', '20000419_apw_eng-NEW', 'Hound-Ch14',\n",
       "       'Stanford', 'artb_004_A1_E1_NEW', 'BWTutorial_chapter1',\n",
       "       'AFGP-2002-602187-Trans', 'boutique.n', 'ChinaOverview',\n",
       "       'SadatAssassination', 'Iran_Missile', 'AFGP-2002-600045-Trans',\n",
       "       'atm', 'Pickett', 'oven.n', 'Syria_NuclearOverview',\n",
       "       'artb_004_A1_E2_NEW', 'NorthKorea_ChemicalOverview', 'SNO-525',\n",
       "       'IntroHongKong', 'WhatToHongKong', 'NorthKorea_NuclearOverview',\n",
       "       '20000420_xin_eng-NEW', 'Fires_9', 'Iran_Chemical', 'Brandeis',\n",
       "       'IZ-060316-01-Trans-1', 'Fires_8', 'IntroJamaica'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all uniqe document names\n",
    "data_df[\"document\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['verb', 'noun', 'adjective', 'adverb', 'prepositional', 'clause',\n",
       "       'art', 'quantifier', 'idiom',\n",
       "       'subordinate clause with subordinating conjunction'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all uniqe phrase types\n",
    "data_df[\"phrase_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Activity_finish', 'Calendric_unit', 'Amounting_to', 'Waiting',\n",
       "       'Verification', 'Desirability', 'Hearsay', 'Desiring',\n",
       "       'Commerce_pay', 'Holding_off_on', 'Possession', 'Information',\n",
       "       'Giving', 'Quantified_mass', 'Temporal_collocation', 'System',\n",
       "       'Needing', 'Predicting', 'Money', 'Awareness', 'Experiencer_focus',\n",
       "       'Intentionally_act', 'Expected_location_of_person',\n",
       "       'Building_subparts', 'Judgment_direct_address', 'Work',\n",
       "       'Speed_description', 'Attempt', 'Statement', 'Activity_done_state',\n",
       "       'Opinion', 'Relative_time', 'Time_vector', 'Causation', 'Gizmo',\n",
       "       'Proportional_quantity', 'Required_event', 'Telling',\n",
       "       'Make_agreement_on_action', 'Having_or_lacking_access',\n",
       "       'Fluidic_motion', 'Assistance', 'Getting', 'Taking_time',\n",
       "       'Creating', 'Grasp', 'Supply', 'Being_necessary', 'Arriving',\n",
       "       'Sending', 'Text', 'Capability', 'History', 'Duration_description',\n",
       "       'Natural_features', 'Locale', 'Distributed_position', 'Expansion',\n",
       "       'Frequency', 'Indigenous_origin', 'People', 'Residence',\n",
       "       'Interior_profile_relation', 'Come_together', 'Hunting',\n",
       "       'Relational_natural_features', 'Undergo_change',\n",
       "       'Measure_duration', 'Change_of_phase', 'Obscurity', 'Progression',\n",
       "       'Activity_start', 'Cause_to_make_progress', 'Food_gathering',\n",
       "       'Identicality', 'Existence', 'Cardinal_numbers', 'Presence',\n",
       "       'Part_inner_outer', 'State_of_entity', 'Network',\n",
       "       'Locative_relation', 'Biological_area', 'Aggregate',\n",
       "       'Being_located', 'Becoming', 'Political_locales', 'Locale_by_use',\n",
       "       'Thriving', 'Inclusion', 'Sign', 'Temporal_subregion',\n",
       "       'Coming_to_be', 'Ordinal_numbers', 'Using', 'Means',\n",
       "       'Accomplishment', 'Stage_of_progress', 'Buildings', 'Cotheme',\n",
       "       'Preventing_or_letting', 'Departing', 'Increment', 'Colonization',\n",
       "       'Origin', 'Cause_change', 'Destiny', 'Part_orientational',\n",
       "       'Continued_state_of_affairs', 'Becoming_aware', 'Name_conferral',\n",
       "       'Being_named', 'Visiting', 'Cogitation', 'Roadways', 'Placing',\n",
       "       'Leadership', 'Sent_items', 'Goal', 'Spatial_contact', 'Partitive',\n",
       "       'Importance', 'Individual_history', 'Response', 'Omen', 'Building',\n",
       "       'People_by_religion', 'Measure_area', 'Surviving',\n",
       "       'Hostile_encounter', 'Predicament', 'Mining', 'Cause_motion',\n",
       "       'Store', 'Scarcity', 'Abandonment', 'Position_on_a_scale',\n",
       "       'Self_motion', 'Scrutiny', 'Sufficiency', 'Achieving_first',\n",
       "       'Distinctiveness', 'Redirecting', 'Agriculture', 'Cause_expansion',\n",
       "       'Supporting', 'Appointing', 'Success_or_failure', 'Concessive',\n",
       "       'Taking', 'Killing', 'People_by_vocation', 'Adjacency',\n",
       "       'Personal_relationship', 'Being_obligated', 'Adopt_selection',\n",
       "       'Earnings_and_losses', 'Event', 'Perception_experience',\n",
       "       'Be_subset_of', 'Age', 'State_continue', 'Have_associated',\n",
       "       'Vehicle', 'Stimulus_focus', 'Serving_in_capacity',\n",
       "       'Locale_by_ownership', 'Travel', 'Commerce_sell', 'Path_shape',\n",
       "       'Direction', 'Posture', 'Emotion_directed', 'Part_whole', 'Size',\n",
       "       'Public_services', 'Measure_linear_extent', 'Businesses',\n",
       "       'Replacing', 'Change_position_on_a_scale', 'Have_as_requirement',\n",
       "       'Cause_change_of_position_on_a_scale', 'Process_continue',\n",
       "       'Electricity', 'Being_employed', 'Process_stop', 'Bringing',\n",
       "       'Commerce_buy', 'Competition', 'Cause_to_amalgamate', 'Removing',\n",
       "       'Membership', 'Deny_or_grant_permission', 'Possibility', 'Luck',\n",
       "       'Opportunity', 'Project', 'Process_start', 'Economy',\n",
       "       'Performers_and_roles', 'Becoming_dry', 'Domain', 'Cause_to_start',\n",
       "       'Containers', 'Cause_change_of_phase', 'Alternatives', 'Attending',\n",
       "       'Touring', 'Intentionally_create', 'Prohibiting_or_licensing',\n",
       "       'Control', 'Legality', 'Fame', 'People_by_age', 'Military',\n",
       "       'Employing', 'Rate_description', 'Sole_instance', 'Purpose',\n",
       "       'Version_sequence', 'Attack', 'Level_of_force_exertion',\n",
       "       'Launch_process', 'Food', 'Activity_ongoing', 'Operating_a_system',\n",
       "       'Relational_political_locales', 'Text_creation',\n",
       "       'Behind_the_scenes', 'Temporary_stay', 'Expensiveness',\n",
       "       'Mental_property', 'Point_of_dispute', 'Committing_crime',\n",
       "       'Make_cognitive_connection', 'Suitability', 'Request',\n",
       "       'Quitting_a_place', 'Firing', 'Process_completed_state',\n",
       "       'Accompaniment', 'Delimitation_of_diversity',\n",
       "       'Objective_influence', 'Substance', 'Boundary',\n",
       "       'Create_physical_artwork', 'Amalgamation', 'Gesture', 'Motion',\n",
       "       'Certainty', 'Rejuvenation', 'Destroying', 'Type',\n",
       "       'Communicate_categorization', 'Exchange', 'Take_place_of',\n",
       "       'Filling', 'Kinship', 'Offering', 'Evidence',\n",
       "       'Judgment_communication', 'Cause_to_perceive', 'Usefulness',\n",
       "       'Occupy_rank', 'Fields', 'Expectation', 'Locale_by_event',\n",
       "       'Difficulty', 'Actually_occurring_entity', 'Likelihood',\n",
       "       'Contingency', 'Process', 'Motion_directional', 'Fire_burning',\n",
       "       'Catching_fire', 'Give_impression', 'Catastrophe',\n",
       "       'Attributed_information', 'Experience_bodily_harm', 'Mass_motion',\n",
       "       'Emptying', 'Fear', 'Cause_to_continue', 'Temperature', 'Openness',\n",
       "       'Change_event_time', 'Weapon', 'Manufacturing',\n",
       "       'Operational_testing', 'Sign_agreement', 'Documents', 'Transfer',\n",
       "       'Infrastructure', 'Degree_of_processing', 'Remainder',\n",
       "       'Measure_mass', 'Research', 'Participation',\n",
       "       'Be_in_agreement_on_action', 'Toxic_substance', 'Commitment',\n",
       "       'Cognitive_connection', 'Artifact', 'Medical_conditions',\n",
       "       'Containing', 'Being_at_risk', 'Coming_up_with',\n",
       "       'Active_substance', 'Activity_stop', 'Discussion',\n",
       "       'Becoming_a_member', 'Range', 'Emergency_fire',\n",
       "       'Expressing_publicly', 'Damaging', 'Experiencer_obj', 'Similarity',\n",
       "       'Setting_fire', 'Successful_action', 'Education_teaching', 'Trial',\n",
       "       'Protecting', 'Representative', 'Make_noise', 'Cause_to_end',\n",
       "       'Law', 'Questioning', 'Rank', 'Historic_event', 'Organization',\n",
       "       'Attention', 'Reference_text', 'Aesthetics', 'Ranked_expectation',\n",
       "       'Communication_response', 'Contacting', 'Social_event', 'Chatting',\n",
       "       'Transition_to_state', 'Forming_relationships', 'Animals',\n",
       "       'Rescuing', 'Submitting_documents', 'Imposing_obligation',\n",
       "       'Putting_out_fire', 'First_rank', 'Communication',\n",
       "       'Location_in_time', 'People_by_residence', 'Cause_harm',\n",
       "       'Firefighting', 'Architectural_part', 'Medical_intervention',\n",
       "       'Body_parts', 'Cause_bodily_experience', 'Awareness_status',\n",
       "       'Installing', 'Criminal_investigation', 'Arson',\n",
       "       'Agree_or_refuse_to_act', 'Assessing', 'Rotting',\n",
       "       'Seeking_to_achieve', 'Reason', 'Thwarting', 'Recovery', 'Revenge',\n",
       "       'Process_end', 'Death', 'Ride_vehicle', 'Operate_vehicle',\n",
       "       'Moving_in_place', 'Estimated_value', 'Evaluative_comparison',\n",
       "       'Commerce_scenario', 'Board_vehicle', 'Differentiation',\n",
       "       'Eventive_affecting', 'Idiosyncrasy', 'Medical_specialties',\n",
       "       'Judgment', 'Team', 'Traversing', 'Endangering',\n",
       "       'Ambient_temperature', 'Change_of_leadership', 'Secrecy_status',\n",
       "       'Cause_to_resume', 'Topic', 'Taking_sides', 'Affirm_or_deny',\n",
       "       'Notification_of_charges', 'Reasoning', 'Coming_to_believe',\n",
       "       'Processing_materials', 'Front_for', 'Foreign_or_domestic_country',\n",
       "       'Familiarity', 'Reveal_secret', 'Ingredients', 'Importing',\n",
       "       'Inspecting', 'Receiving', 'Willingness', 'Amassing',\n",
       "       'Withdraw_from_participation', 'Compliance', 'Reporting',\n",
       "       'Relation', 'Speak_on_topic', 'Attempt_suasion', 'Activity_pause',\n",
       "       'Encoding', 'Collaboration', 'Completeness', 'Ratification',\n",
       "       'Source_of_getting', 'Referring_by_name', 'Measurable_attributes',\n",
       "       'Bearing_arms', 'Shoot_projectiles', 'Seeking', 'Resolve_problem',\n",
       "       'Risky_situation', 'Trust', 'Reliance', 'Grinding', 'Used_up',\n",
       "       'Reshaping', 'Ground_up', 'Categorization',\n",
       "       'Unattributed_information', 'Estimating', 'Instance', 'Candidness',\n",
       "       'Partiality', 'Translating', 'Exporting', 'Rate_quantification',\n",
       "       'Explaining_the_facts', 'Event_instance', 'Releasing', 'Prison',\n",
       "       'Reliance_on_expectation', 'Path_traveled', 'Impact', 'Locating',\n",
       "       'Unemployment_rate', 'Attitude_description', 'Weather', 'Feeling',\n",
       "       'Degree', 'Escaping', 'Desirable_event', 'Terrorism',\n",
       "       'Activity_prepare', 'Practice', 'Commemorative', 'Expertise',\n",
       "       'Examination', 'Delivery', 'Medical_professionals', 'Deciding',\n",
       "       'Run_risk', 'Being_in_control', 'Wearing', 'Clothing',\n",
       "       'Member_of_military', 'Defending', 'Proliferating_in_number',\n",
       "       'Color', 'Smuggling', 'Intoxicants', 'Obviousness', 'Connectors',\n",
       "       'Religious_belief', 'Hiring', 'Kidnapping', 'Offenses', 'Theft',\n",
       "       'Choosing', 'Dimension', 'Motion_noise', 'Shapes', 'Eclipse',\n",
       "       'Being_questionable', 'Aiming', 'Conduct', 'Perception_active',\n",
       "       'Scouring', 'Hiding_objects', 'People_by_origin', 'Strictness',\n",
       "       'Entity', 'Dispersal', 'Storing', 'Suspicion', 'Activity_resume',\n",
       "       'Fleeing', 'Forgoing', 'Labeling', 'People_by_jurisdiction',\n",
       "       'Quarreling', 'Social_connection', 'Subjective_influence',\n",
       "       'Subversion', 'Sentencing', 'Adducing', 'Justifying', 'Attaching',\n",
       "       'Lively_place', 'Abounding_with', 'Being_operational',\n",
       "       'Making_faces', 'Contrition', 'Facial_expression',\n",
       "       'Communication_manner', 'Connecting_architecture',\n",
       "       'Reading_activity', 'Halt', 'Directional_locative_relation',\n",
       "       'Bungling', 'Sensation', 'Non-gradable_proximity',\n",
       "       'Temporal_pattern', 'Memory', 'Becoming_silent', 'Sounds',\n",
       "       'Being_in_operation', 'Mental_stimulus_stimulus_focus',\n",
       "       'Body_movement', 'Rite', 'Communication_noise',\n",
       "       'Physical_artworks', 'Ingestion', 'Change_posture', 'Meet_with',\n",
       "       'Breathing', 'Avoiding', 'Transition_to_a_quality',\n",
       "       'Biological_urge', 'Typicality', 'Dead_or_alive',\n",
       "       'Be_in_agreement_on_assessment', 'Duration_relation',\n",
       "       'Surrendering_possession', 'Execute_plan', 'Irregular_combatants',\n",
       "       'Morality_evaluation', 'Cause_to_fragment', 'Emphasizing',\n",
       "       'Emotion_active', 'Cure', 'Ammunition', 'Deserving',\n",
       "       'Inhibit_movement', 'Finish_competition', 'Arrest', 'Summarizing',\n",
       "       'Nuclear_process', 'Institutions', 'Emanating', 'Invading',\n",
       "       'Margin_of_resolution', 'Correctness',\n",
       "       'People_along_political_spectrum', 'Alliance',\n",
       "       'Reforming_a_system', 'Negation', 'Remembering_experience',\n",
       "       'Extreme_point', 'Recording', 'Spatial_co-location', 'Proportion',\n",
       "       'Judicial_body', 'Disgraceful_situation', 'Wealthiness',\n",
       "       'Confronting_problem', 'Appellations', 'Becoming_separated',\n",
       "       'Relational_quantity', 'Prevent_or_allow_possession', 'Exemplar',\n",
       "       'Extradition', 'Reassuring', 'Arranging', 'Hindering', 'Detaining',\n",
       "       'Quantity', 'Judgment_of_intensity', 'Law_enforcement_agency',\n",
       "       'Subordinates_and_superiors', 'Timespan', 'Probability',\n",
       "       'Preliminaries', 'Respond_to_proposal', 'Interrupt_process',\n",
       "       'Cause_change_of_strength', 'Light_movement', 'Vocalizations',\n",
       "       'Closure', 'Emotions_by_stimulus', 'Clothing_parts',\n",
       "       'Noise_makers', 'Manipulation', 'Preserving', 'Biological_entity',\n",
       "       'Part_piece', 'Separating', 'Retaining', 'Cause_emotion',\n",
       "       'Location_of_light', 'Custom', 'Just_found_out',\n",
       "       'Remembering_information', 'Punctual_perception', 'Daring',\n",
       "       'Accoutrements', 'Social_interaction_evaluation', 'Attempt_means',\n",
       "       'Tolerating', 'Being_active', 'Level_of_force_resistance',\n",
       "       'Complaining', 'Claim_ownership', 'Being_in_captivity',\n",
       "       'Artificiality', 'Color_qualities', 'Sleep',\n",
       "       'Cause_to_move_in_place', 'Rebellion', 'Fullness',\n",
       "       'Sidereal_appearance', 'Make_acquaintance', 'Hit_target',\n",
       "       'Change_tool', 'Verdict', 'Legal_rulings', 'Inclination',\n",
       "       'Cause_to_experience', 'Imprisonment', 'Ingest_substance',\n",
       "       'Try_defendant', 'Regard', 'Isolated_places', 'Suasion', 'Cutting',\n",
       "       'Dominate_situation', 'Beat_opponent', 'Planned_trajectory',\n",
       "       'Fairness_evaluation', 'Linguistic_meaning', 'Volubility',\n",
       "       'Simple_name', 'Manner', 'Trendiness', 'Compatibility',\n",
       "       'Manipulate_into_doing', 'Piracy', 'Activity_ready_state',\n",
       "       'Change_event_duration', 'Measure_volume', 'First_experience',\n",
       "       'Billing', 'Renunciation', 'Left_to_do', 'Rest', 'Giving_birth',\n",
       "       'Addiction', 'Abusing', 'Ceasing_to_be', 'Being_relevant',\n",
       "       'Labor_product', 'Evoking', 'Stinginess', 'Prevarication',\n",
       "       'People_by_morality', 'Excreting', 'Rewards_and_punishments',\n",
       "       'Institutionalization', 'Being_in_effect', 'Craft', 'Undergoing',\n",
       "       'Being_born', 'Getting_vehicle_underway', 'Precipitation',\n",
       "       'Intentionally_affect', 'Renting', 'Intentional_traversing',\n",
       "       'Setting_out', 'Duplication', 'Conquering', 'Soaking_up',\n",
       "       'Part_ordered_segments', 'Pattern', 'Diversity', 'Besieging',\n",
       "       'Being_wet', 'Rape', 'Guilt_or_innocence', 'Immobilization',\n",
       "       'Giving_in', 'Terms_of_agreement', 'Render_nonfunctional',\n",
       "       'Fastener', 'Intercepting', 'Commercial_transaction',\n",
       "       'Going_back_on_a_commitment', 'Being_attached',\n",
       "       'Cause_to_make_noise', 'Heralding', 'Sequence', 'Memorization',\n",
       "       'Simple_naming', 'Mental_stimulus_exp_focus', 'Cooking_creation',\n",
       "       'Fall_asleep', 'Body_mark', 'Process_resume', 'Gathering_up',\n",
       "       'Reading_perception', 'Execution', 'Enforcing',\n",
       "       'Improvement_or_decline', 'Come_down_with', 'Being_incarcerated',\n",
       "       'Using_resource', 'Change_post-state', 'Breaking_out_captive',\n",
       "       'Co-association', 'Offshoot', 'Frugality', 'Medium', 'Coincidence',\n",
       "       'Quitting', 'Shopping', 'Sharpness', 'Change_direction',\n",
       "       'Assemble', 'Being_dry', 'Being_in_category', 'Reparation',\n",
       "       'Waking_up', 'Proper_reference', 'Popularity',\n",
       "       'Chemical-sense_description', 'Out_of_existence',\n",
       "       'Within_distance', 'Cause_to_wake', 'Accuracy', 'Sound_level',\n",
       "       'Trying_out', 'Emotions_of_mental_activity', 'Turning_out',\n",
       "       'Forging', 'Tasting', 'Manner_of_life', 'Growing_food',\n",
       "       'Hit_or_miss', 'Exchange_currency', 'Capacity',\n",
       "       'Body_description_holistic', 'Create_representation',\n",
       "       'Disembarking', 'Performing_arts', 'Apply_heat',\n",
       "       'Change_operational_state', 'Reading_aloud', 'Hospitality',\n",
       "       'Ineffability', 'Carry_goods', 'Prominence',\n",
       "       'Undergo_transformation', 'Abundance', 'Extreme_value',\n",
       "       'Impression', 'Dominate_competitor', 'System_complexity',\n",
       "       'Sociability', 'Win_prize', 'Cause_fluidic_motion', 'Simultaneity',\n",
       "       'Preference', 'Cause_impact', 'Convey_importance', 'Scope',\n",
       "       'Aging', 'Misdeed', 'Arraignment', 'Bail_decision',\n",
       "       'Entering_of_plea', 'Adjusting', 'Beyond_compare', 'Robbery',\n",
       "       'Forgiveness', 'Making_arrangements', 'Indicating'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all uniqe semantic frames\n",
    "data_df[\"semantic_frame\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>semantic_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>A Brief History</td>\n",
       "      <td>history</td>\n",
       "      <td>noun</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>A Brief History</td>\n",
       "      <td>brief</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Duration_description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>Early Habitation</td>\n",
       "      <td>early</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Relative_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>The inhabited history of the Las Vegas Valley ...</td>\n",
       "      <td>valley</td>\n",
       "      <td>noun</td>\n",
       "      <td>Natural_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>The inhabited history of the Las Vegas Valley ...</td>\n",
       "      <td>area</td>\n",
       "      <td>noun</td>\n",
       "      <td>Locale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28936</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>Jamaica is an island with a strong personality...</td>\n",
       "      <td>strong</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Level_of_force_exertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28937</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>Jamaica is an island with a strong personality...</td>\n",
       "      <td>wait</td>\n",
       "      <td>verb</td>\n",
       "      <td>Waiting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28938</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>Jamaica is an island with a strong personality...</td>\n",
       "      <td>wing</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28939</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>It comes out to meet you .</td>\n",
       "      <td>come</td>\n",
       "      <td>verb</td>\n",
       "      <td>Arriving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28940</th>\n",
       "      <td>ANC</td>\n",
       "      <td>IntroJamaica</td>\n",
       "      <td>It comes out to meet you .</td>\n",
       "      <td>meet</td>\n",
       "      <td>verb</td>\n",
       "      <td>Make_acquaintance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8345 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      corpus           document  \\\n",
       "137      ANC  HistoryOfLasVegas   \n",
       "138      ANC  HistoryOfLasVegas   \n",
       "139      ANC  HistoryOfLasVegas   \n",
       "140      ANC  HistoryOfLasVegas   \n",
       "141      ANC  HistoryOfLasVegas   \n",
       "...      ...                ...   \n",
       "28936    ANC       IntroJamaica   \n",
       "28937    ANC       IntroJamaica   \n",
       "28938    ANC       IntroJamaica   \n",
       "28939    ANC       IntroJamaica   \n",
       "28940    ANC       IntroJamaica   \n",
       "\n",
       "                                                sentence     word phrase_type  \\\n",
       "137                                      A Brief History  history        noun   \n",
       "138                                      A Brief History    brief   adjective   \n",
       "139                                     Early Habitation    early   adjective   \n",
       "140    The inhabited history of the Las Vegas Valley ...   valley        noun   \n",
       "141    The inhabited history of the Las Vegas Valley ...     area        noun   \n",
       "...                                                  ...      ...         ...   \n",
       "28936  Jamaica is an island with a strong personality...   strong   adjective   \n",
       "28937  Jamaica is an island with a strong personality...     wait        verb   \n",
       "28938  Jamaica is an island with a strong personality...     wing        noun   \n",
       "28939                         It comes out to meet you .     come        verb   \n",
       "28940                         It comes out to meet you .     meet        verb   \n",
       "\n",
       "                semantic_frame  \n",
       "137                    History  \n",
       "138       Duration_description  \n",
       "139              Relative_time  \n",
       "140           Natural_features  \n",
       "141                     Locale  \n",
       "...                        ...  \n",
       "28936  Level_of_force_exertion  \n",
       "28937                  Waiting  \n",
       "28938        Building_subparts  \n",
       "28939                 Arriving  \n",
       "28940        Make_acquaintance  \n",
       "\n",
       "[8345 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from the ANC corpus\n",
    "target_corpus = \"ANC\"\n",
    "data_df.query(\"corpus == @target_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>semantic_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>Several weeks later he was asked -- then order...</td>\n",
       "      <td>room</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>Several weeks later he was asked -- then order...</td>\n",
       "      <td>room</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>ANC</td>\n",
       "      <td>HistoryOfLasVegas</td>\n",
       "      <td>Over 20,000 additional hotel rooms have been a...</td>\n",
       "      <td>room</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>ANC</td>\n",
       "      <td>StephanopoulosCrimes</td>\n",
       "      <td>Near the end of The War Room , Stephanopoulos ...</td>\n",
       "      <td>room</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16490</th>\n",
       "      <td>ANC</td>\n",
       "      <td>110CYL069</td>\n",
       "      <td>In the short while since Goodwill helped him f...</td>\n",
       "      <td>room</td>\n",
       "      <td>noun</td>\n",
       "      <td>Building_subparts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      corpus              document  \\\n",
       "802      ANC     HistoryOfLasVegas   \n",
       "806      ANC     HistoryOfLasVegas   \n",
       "954      ANC     HistoryOfLasVegas   \n",
       "11431    ANC  StephanopoulosCrimes   \n",
       "16490    ANC             110CYL069   \n",
       "\n",
       "                                                sentence  word phrase_type  \\\n",
       "802    Several weeks later he was asked -- then order...  room        noun   \n",
       "806    Several weeks later he was asked -- then order...  room        noun   \n",
       "954    Over 20,000 additional hotel rooms have been a...  room        noun   \n",
       "11431  Near the end of The War Room , Stephanopoulos ...  room        noun   \n",
       "16490  In the short while since Goodwill helped him f...  room        noun   \n",
       "\n",
       "          semantic_frame  \n",
       "802    Building_subparts  \n",
       "806    Building_subparts  \n",
       "954    Building_subparts  \n",
       "11431  Building_subparts  \n",
       "16490  Building_subparts  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from the ANC corpus with the \"Building_subparts\" semantic frame\n",
    "target_corpus = \"ANC\"\n",
    "target_semantic_frame = \"Building_subparts\"\n",
    "data_df.query(\"corpus == @target_corpus and semantic_frame == @target_semantic_frame\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LUCorpus-v0.3': 1432,\n",
       " 'ANC': 3770,\n",
       " 'WikiTexts': 459,\n",
       " 'NTI': 5146,\n",
       " 'PropBank': 830,\n",
       " 'Miscellaneous': 1448,\n",
       " 'KBEval': 687}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over all rows and count number of words with noun phrase_type for each corpus\n",
    "noun_count_dict = {corpus: 0 for corpus in data_df['corpus'].unique()}\n",
    "\n",
    "for index, row in data_df.iterrows():\n",
    "    if row['phrase_type'] == \"noun\":\n",
    "        noun_count_dict[row[\"corpus\"]] += 1\n",
    "\n",
    "noun_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HistoryOfLasVegas': 361,\n",
       " '110CYL200': 41,\n",
       " 'chapter1_911report': 16,\n",
       " '112C-L013': 82,\n",
       " 'journal_christine': 45,\n",
       " '110CYL070': 33,\n",
       " 'StephanopoulosCrimes': 53,\n",
       " '110CYL072': 25,\n",
       " '110CYL067': 61,\n",
       " 'HistoryOfGreece': 406,\n",
       " 'HistoryOfJerusalem': 335,\n",
       " '110CYL069': 82,\n",
       " 'WhereToHongKong': 1527,\n",
       " '110CYL068': 67,\n",
       " 'IntroOfDublin': 227,\n",
       " 'EntrepreneurAsMadonna': 67,\n",
       " 'IntroHongKong': 118,\n",
       " 'WhatToHongKong': 39,\n",
       " 'IntroJamaica': 185}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate over all documents in the ANC corpus, and count words with noun phrase type\n",
    "noun_count_dict = {corpus: 0 for corpus in data_df.query(\"corpus == 'ANC'\")['document'].unique()}\n",
    "\n",
    "for index, row in data_df.query(\"corpus == 'ANC'\").iterrows():\n",
    "    if row['phrase_type'] == \"noun\":\n",
    "        noun_count_dict[row[\"document\"]] += 1\n",
    "\n",
    "noun_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats\n",
    "This section of the notebook has some high-level summary statistics for the parsed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of corpus and documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of corpus: 7 | Number of documents: 102\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of corpus: {n_corpus} | Number of documents: {n_docs}\".format(n_corpus=len(parsed_files_df['corpus'].unique()),\n",
    "                                                                            n_docs=len(parsed_files_df['document'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents corpus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corpus\n",
       "ANC              19\n",
       "KBEval            9\n",
       "LUCorpus-v0.3    21\n",
       "Miscellaneous    11\n",
       "NTI              20\n",
       "PropBank          6\n",
       "WikiTexts        16\n",
       "Name: document, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of documents corpus\")\n",
    "parsed_files_df.groupby(\"corpus\")[\"document\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique number of sentences: 4938\n",
      "\n",
      "Number of sentences per corpus: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corpus\n",
       "ANC              1353\n",
       "KBEval            436\n",
       "LUCorpus-v0.3     601\n",
       "Miscellaneous     732\n",
       "NTI              1324\n",
       "PropBank          325\n",
       "WikiTexts         196\n",
       "Name: sentence, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total unique number of sentences: {0}\\n\\nNumber of sentences per corpus: \".format(len(parsed_files_df['sentence'].unique())))\n",
    "parsed_files_df.groupby(\"corpus\")[\"sentence\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive stats of number of sentences per document\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    102.000000\n",
       "mean      48.735294\n",
       "std       70.664586\n",
       "min        1.000000\n",
       "25%       12.000000\n",
       "50%       29.000000\n",
       "75%       58.000000\n",
       "max      499.000000\n",
       "Name: sentence, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Descriptive stats of number of sentences per document\")\n",
    "parsed_files_df.groupby(\"document\")[\"sentence\"].nunique().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique frames: 28941\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique frames: {0}\".format(len(parsed_files_df['semantic_frame'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive stats of number of semantic frames per sentence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4938.000000\n",
       "mean        5.254962\n",
       "std         3.295641\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         5.000000\n",
       "75%         7.000000\n",
       "max        23.000000\n",
       "Name: semantic_frame, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Descriptive stats of number of semantic frames per sentence\")\n",
    "parsed_files_df.groupby(\"sentence\")[\"semantic_frame\"].nunique().describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
